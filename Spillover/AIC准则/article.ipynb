{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472dbb8a-8d93-4bd6-bb4f-e6d56242397b",
   "metadata": {},
   "source": [
    "# Akaike Information Criterion (AIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b0d62-844a-4487-9867-69626d7c25c4",
   "metadata": {},
   "source": [
    "The Akaike Information Criterion (AIC) is a statistical measure used to evaluate and compare the goodness-of-fit of different models. It is particularly useful in model selection, as it helps identify the model that best balances fit and complexity. AIC is commonly used in time series analysis, regression models, and other areas where multiple models are being compared.\n",
    "\n",
    "## Definition\n",
    "The AIC is defined as:\n",
    "\n",
    "$$\n",
    "\\text{AIC} = 2k - 2\\ln(L)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ k $ is the number of parameters in the model.\n",
    "- $ L $ is the maximum likelihood of the model, which measures how well the model fits the data.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. **Number of Parameters ($ k $)**: Represents the modelâ€™s complexity. Models with more parameters generally fit the training data better but can lead to overfitting.\n",
    "\n",
    "2. **Log-Likelihood ($ \\ln(L) $)**: Represents how well the model fits the observed data. A higher likelihood indicates a better fit to the data.\n",
    "\n",
    "## Interpretation\n",
    "\n",
    "- **Minimization Criterion**: The objective is to **minimize** the AIC value when comparing models. The model with the lowest AIC is considered$$he best among the set of candidate models, as it balances goodness-of-fit and model simplicity.\n",
    "  \n",
    "- **Trade-off Between Fit and Complexity**: AIC penalizes models with a larger number of parameters, thereby discouraging overfitting. This penalty is proportional to the number of parameters, encouraging the selection of more parsimonious models.\n",
    "\n",
    "## Use in Model Selection\n",
    "\n",
    "1. **Comparing Models**: AIC is used to compare multiple models, where the model with the smallest AIC is preferred. It does not test the models for statistical significance; it only ranks them.\n",
    "\n",
    "2. **Relative Measure**: AIC values are only meaningful when comparing different models on the same dataset. An isolated AIC value has no absolute interpretation.\n",
    "\n",
    "## Example of Using AIC for Model Selection\n",
    "\n",
    "Suppose we have two competing models for a time series dataset:\n",
    "\n",
    "- **Model 1**: A simple AR(1) model with 2 parameters (intercept + AR(1) coefficient) and a log-likelihood of -120.\n",
    "\n",
    "$$\n",
    "\\text{AIC}_{\\text{Model 1}} = 2 \\times 2 - 2 \\times (-120) = 4 + 240 = 244\n",
    "$$\n",
    "\n",
    "- **Model 2**: An AR(2) model with 3 parameters (intercept + AR(1) coefficient + AR(2) coefficient) and a log-likelihood of -115.\n",
    "\n",
    "$$\n",
    "\\text{AIC}_{\\text{Model 2}} = 2 \\times 3 - 2 \\times (-115) = 6 + 230 = 236\n",
    "$$\n",
    "\n",
    "In this case, **Model 2** has a lower AIC value (236) than **Model 1** (244), indicating that Model 2 is the better choice as it offers a better fit without adding too much complexity.\n",
    "\n",
    "## Limitations of AIC\n",
    "\n",
    "1. **Sample Size Sensitivity**: AIC can be biased in small samples. An alternative, the **Corrected AIC (AICc)**, introduces a correction term for finite sample sizes.\n",
    "  \n",
    "2. **Assumption of Model Correctness**: AIC assumes that one of the models being compared is the true model. In practice, this assumption may not always hold.\n",
    "\n",
    "3. **Non-Nested Models**: AIC is most useful for comparing non-nested models (i.e., models that are not special cases of each other). For nested models, likelihood ratio tests might be more appropriate.\n",
    "\n",
    "4. **No Absolute Benchmark**: AIC provides a relative comparison between models, but it does not indicate how well the models fit the data in an absolute sense.\n",
    "\n",
    "## Extensions and Alternatives\n",
    "1. **Corrected AIC (AICc)**: Adjusts for small sample sizes and is recommended when the sample size is small relative to the number of parameters.\n",
    "  \n",
    "2. **Bayesian Information Criterion (BIC)**: Adds a stricter penalty for the number of parameters and tends to select simpler models.\n",
    "\n",
    "3. **Deviance Information Criterion (DIC)**: Used for hierarchical models, incorporating model complexity and fit.\n",
    "\n",
    "4. **Hannan-Quinn Criterion (HQC)**: An alternative criterion that lies between AIC and BIC in terms of the penalty for additional parameters.\n",
    "\n",
    "## Conclusion\n",
    "The AIC is a powerful tool for model comparison and selection, providing a balance between fit and complexity. It helps avoid overfitting by penalizing models with unnecessary parameters, guiding researchers and practitioners towards more parsimonious models that generalize better to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea46a77-7eb5-4676-8517-3cebd61509c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
